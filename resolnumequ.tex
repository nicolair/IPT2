\input{ipt.tex}
%En tete et pied de page
\lhead{Cours IPT}
\chead{Cours 6: Résolution numérique d'équations aux inconnues réelles le 07/0117}
\begin{document}
\begin{algorithm}
  \Donnees{\;
    $a$ et $b$ deux flottants définissant l'intervalle\;
    $f$ une fonction renvoyant un flottant pour toute donnée (flottant) entre $a$ et $b$\;
    $e$ flottant : l'erreur doit être inférieure à $e$\;
  }
  \Comment{initialisation}
  $va\leftarrow f(a)$\;
  $vb\leftarrow f(b)$\;
  
  \Tq{ $b-a > e$}{
    $m\leftarrow  \frac{a+b}{2}$ \;
    $vm \leftarrow f(m)$\;
    \eSi{ $vm\, va \leq 0$}{
      $b \leftarrow m$ \;
      $vb \leftarrow vm$ \;
    }{
      $a \leftarrow m$ \;
      $va \leftarrow vm$ \;
    }
  }
  Renvoyer $a$\;
  \caption{Méthode dichotomique}
  \label{resolnumequ_1}
\end{algorithm}


\section{Principes généraux.}
Toute équation à une inconnue dont on cherche les solutions réelles peut se mettre sous la forme
\begin{displaymath}
  f(x) = 0
\end{displaymath}
où $f$ est une fonction définie dans une partie $I$ de $\R$. La recherche des valeurs numériques approchées des solutions de cette équation comporte deux étapes.\newline
La première est celle de la \emph{séparation} des solutions. Elle consiste à trouver des intervalles $J$ de $I$ telles chaque $J$ contienne une unique solution et que la restriction de $f$ à $J$ ait de \og bonnes\fg  propriétés. \newline 
La deuxième étape est celle de l'évaluation numérique de chaque solution. Elle consiste à utiliser un algorithme, avec des données spécifiques à chaque intervalle $J$, et renvoyant une valeur numérique approchant la solution dans $J$ avec une erreur plus petite qu'une valeur prescrite. Les bonnes propriétés citées plus haut assurent la validité mathématique de l'algorithme choisi.\newline
On ne propose pas ici de méthode de séparation des racines mais deux méthodes classiques d'évaluation numérique.

\section{Méthode dichotomique.}
\subsection{Les propriétés à vérifier.}
La partie $J$ est un segment $[a,b]$, la fonction $f$ est continue sur $J$ et $f(a)f(b)<0$. Dans ces conditions, le thèorème des valeurs intermédiaires assure que $f$ admet un zéro dans $J$. Si de plus la fonction est strictement monotone alors ce zéro est l'unique solution dans $J$. 

\subsection{Terminaison et correction}
La valeur désignée par $b-a$ après $k$ exécutions de la boucle est $\frac{1}{2^k}(b-a)$. Comme les valeurs renvoyées sont des flottants (binaires normalisés), on choisit d'imposer un majorant de l'erreur de la forme $\frac{1}{2^p}$. L'expression 
\begin{displaymath}
p-k + \lceil \frac{\ln(b-a)}{\ln 2}\rceil  
\end{displaymath}
 est  un variant car elle décroit strictement et, tant que les conditions sont réalisées,
\begin{multline*}
  \frac{b-a}{2^k} >\frac{1}{2^p} \Rightarrow 
  \ln(b-a) - k\ln 2 > -p\ln 2 \Rightarrow p-k > -\frac{\ln(b-a)}{\ln 2} \\
  \Rightarrow p-k + \lceil \frac{\ln(b-a)}{\ln 2}\rceil \geq p-k + \frac{\ln(b-a)}{\ln 2} >0
\end{multline*}
L'algorithme termine donc et le nombre maximal d'itérations est de l'ordre de $p$.
L'expression booléenne
\begin{displaymath}
  f(a)f(b)\leq 0
\end{displaymath}
est un invariant de la boucle. Cet invariant assure qu'il existe toujours un zéro de la fonction dans l'intervalle et donc que chaque nombre dans le segment est une valeur approchée à $e$ près d'un zéro. Pratiquement, on renvoie une extrémité ou on peut chercher à faire un peu mieux ( voir exercice).

\subsection{Implémentation en Python}
\lstinputlisting[firstline=11, lastline=25]{resolnumequ.py}
On n'est pas obligé de donner un nom à la fonction que l'on passe à la procédure \texttt{dicho}. L'opérateur \texttt{lambda} permet de passer des fonctions \emph{anonymes} directement lors de l'appel.
\lstinputlisting[firstline=27, lastline=28]{resolnumequ.py}

\subsection{Exercice}
Modifier le code Python du paragraphe précédent pour renvoyer le milieu du segment, la meilleure des deux extrémités (celle qui a la plus petite valeur de la fonction), une moyenne des extrémités pondérées à l'aide des valeurs de la fonction de manière à privilégier l'extrémité dont la valeur est la plus petite.\newline
Pour le calcul approché de $\sqrt{2}$, tracer sur un même graphique les courbes des erreurs pour chaque méthode en fonction du nombre d'itérations. On prendra pour valeur \og exacte\fg la valeur renvoyée par la fonction \texttt{sqrt} de la bibiothèque \texttt{math}.

\section{Méthode de Newton.}
\begin{algorithm}
  \Donnees{\;
    $b$ flottant extrémité droite de l'intervalle\;
    $f$ une fonction renvoyant un flottant pour toute donnée (flottant) entre $a$ et $b$\;
    $g$ une fonction représentant la dérivée de $f$\;
    $e$ flottant : l'erreur doit être inférieure à $e$\;
  }
  \Comment{initialisation}
  $bb \leftarrow b - f(b)/g(b)$\;  
  \Tq{ $b - bb > e$}{
    $b \leftarrow bb$\;
    $bb \leftarrow b - f(b)/g(b)$\;
  }
  Renvoyer $bb$\;
  \caption{Méthode de Newton}
  \label{resolnumequ_2}
\end{algorithm}

\subsection{Les propriétés à vérifier.}
L'algorithme de Newton converge lorsque $J$ est un segment $[a,b]$ et que la restriction de $f$ à $J$ est de classe $\mathcal{C}^2$, strictement croissante, convexe et telle que $f(a)<0$, $f(b)>0$. On peut être amené à remplacer $f$ par $-f$ pour que la condition de croissance soit vérifiée. 

\subsection{Principes mathématiques}
Sous les conditions indiquées au dessus, il existe dans l'intervalle $[a,b]$ une unique solution notée $c$. La méthode de Newton consiste à remplacer systématiquement l'extrémité droite de l'intervalle par le point d'intersection de la tangente en ce point avec l'axe des abscisses. L'algorithme fonctionne aussi dans le cas où la fonction est \emph{concave} au lieu de convexe, il convient alors de remplacer l'extrémité gauche de l'intervalle. Ce cas ne sera pas détaillé.\newline
Avec le formalisme des suites, cela se traduit par une suite définie par récurrence
\begin{displaymath}
  b_0 = b,\hspace{0.5cm}\forall n\in\N,\;b_{n+1} = b_n -\frac{f(b_n)}{f'(b_n)}
\end{displaymath}
On peut montrer que la suite $\left( b_n\right)_{n\in \N}$ est strictement décroissante et converge vers l'unique solution $c$. On dispose de majorations de l'erreur très intéressantes
\begin{displaymath}
  0< b_n -c \leq \frac{M_2}{2m_1}(b_{n-1}-b_n)^2,\hspace{1cm} 0< b_{n+1} -c \leq \frac{M_2}{2m_1}(c-b_n)^2
\end{displaymath}
avec $m_1 = \min_{[a,b]} f'>0$ et $M_2 = \max_{[a,b]}\left|f''\right|$.\newline
On remarque que la fonction étant de classe $\mathcal{C}^2$, les deux premières dérivées sont continues donc bornées et atteignent leurs bornes. De plus, $f'$ est strictement positive car la fonction est strictement croissante.\newline
Cette méthode revient à remplacer un problème de recherche de zéro par un problème de recherche de \emph{point fixe}. Définissons une fonction $\Phi$ par
\begin{displaymath}
  \Phi(x) = x -\frac{f(x)}{f'(x)}
\end{displaymath}
alors:
\begin{displaymath}
  f(x) = 0 \Leftrightarrow \Phi(x) = x
\end{displaymath}
Un zéro $c$ de $f$ est aussi un point fixe de $\Phi$ \og super-attractif\fg c'est à dire que $\Phi'(c)=0$. Cette propriété explique la convergence très rapide (quadratique) de la méthode. Les majorations de l'erreur fournies prouvent que le nombre de décimales exactes double à chaque étape.

\subsection{Terminaison et correction}
L'algorithme en lui même est très simple, l'exécution et la terminaison reposent entièrement sur les propriétés de la fonction $f$ et les résultats mathématiques qui en découlent.\newline
Le calcul de la dérivée peut poser problème. On peut la faire calculer par une bibliothèque de calcul formel avant d'évaluer numériquement ses valeurs ou bien renvoyer directement des évaluations calculées uniquement à partir de $f$.

\subsection{Implémentation en Python.}
\lstinputlisting[firstline= 85, lastline= 102]{ resolnumequ.py}

\subsection{Exercice}
La méthode de Newton fonctionne encore dans le champ complexe. Par exemple, appliquée à la fonction $z\mapsto z^3 -1$, on peut démontrer qu'elle converge sauf pour un ensemble dénombrable de valeurs initiales. Evidemment, lorsqu'elle converge, c'est vers une des racines cubiques de l'unité c'est à dire $1$, $j$, $j^2$.\newline
Dessiner les bassins d'attraction de ces racines en coloriant chaque point suivant la limite de la suite de Newton formée avec cette condition initiale.

\section{Correction de l'exercice sur la dichotomie}
Ne pas oublier de passer les commandes \newline
\texttt{import math} et \texttt{import matplotlib.pyplot as plt}\newline
d'importation de la bibliothèque de maths et d'outils graphiques au début du code.
\lstinputlisting[firstline= 30, lastline= 41]{ resolnumequ.py}
\lstinputlisting[firstline= 43, lastline= 57]{ resolnumequ.py}
\lstinputlisting[firstline= 59, lastline= 70]{ resolnumequ.py}
Appels et comparaison des courbes:
\begin{verbatim}
r2 = math.sqrt(2)

courbe1 = [math.log(abs(dicho1(r,1,2,i)-r2)) for i in range(1,30)]
courbe2 = [math.log(abs(dicho2(r,1,2,i)-r2)) for i in range(1,30)]
courbe3 = [math.log(abs(dicho3(r,1,2,i)-r2)) for i in range(1,15)]
plt.figure(1)
plt.plot(courbe1,'blue') # milieu du segment
plt.plot(courbe2, 'red') # meilleur bord
plt.plot(courbe3, 'green') # moyenne pondérée
plt.show(1)
\end{verbatim}

\section{Correction exercice sur méthode de Newton}
Définition des complexes $j$ et $j^2$ et d'une fonction qui associe une couleur aux points dans un voisinage des racines cubiques de $1$.
\lstinputlisting[firstline= 105, lastline= 116]{ resolnumequ.py}
Quadrillage et coloriage de la condition initiale suivant le résultat de la méthode de Newton
\lstinputlisting[firstline= 118, lastline= 138]{ resolnumequ.py}

\end{document}
